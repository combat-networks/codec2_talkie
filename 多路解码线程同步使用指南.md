# 🎵 多路解码线程同步使用指南

## 📋 概述

本指南详细介绍了如何在Codec2 Talkie项目中集成和使用多路解码线程同步功能，确保多路音频能够正确解码、混音和输出。

## 🚀 快速开始

### 1. 基本集成步骤

#### 1.1 初始化同步管理器

```java
// 在AppWorker中初始化
public class AppWorker extends Thread {
    private AudioSyncManager audioSyncManager;
    private AudioMixer audioMixer;
    private AudioTrack systemAudioPlayer;
    
    @Override
    public void run() {
        android.os.Process.setThreadPriority(Process.THREAD_PRIORITY_URGENT_AUDIO);
        Looper.prepare();
        
        // 初始化同步管理器
        initializeAudioSync();
        
        // 原有逻辑...
        Looper.loop();
    }
    
    private void initializeAudioSync() {
        // 创建音频混音器
        audioMixer = new AudioMixer();
        audioMixer.initialize();
        
        // 创建同步管理器
        audioSyncManager = new AudioSyncManager();
        audioSyncManager.initialize();
        
        Log.i("AppWorker", "Audio sync initialized");
    }
}
```

#### 1.2 注册音频通道

```java
// 注册多路音频通道
public void registerAudioChannels() {
    // 注册通道1 (Codec2)
    audioSyncManager.registerChannel("channel_1");
    audioMixer.addChannel("channel_1");
    
    // 注册通道2 (Opus)
    audioSyncManager.registerChannel("channel_2");
    audioMixer.addChannel("channel_2");
    
    // 设置通道增益
    audioMixer.setChannelGain("channel_1", 1.0f);
    audioMixer.setChannelGain("channel_2", 0.8f);
}
```

### 2. 处理音频数据

#### 2.1 接收音频帧

```java
// 在协议栈接收处理中
public void onReceiveCompressedAudio(String src, String dst, byte[] audioEncodedFrame) {
    // 确定通道ID
    String channelId = determineChannelId(src, dst);
    
    // 处理音频帧同步
    audioSyncManager.processAudioFrame(channelId, audioEncodedFrame);
    
    // 原有解码逻辑...
    short[] decodedAudio = performDecode(audioEncodedFrame);
    
    // 创建音频帧
    AudioFrame audioFrame = new AudioFrame(channelId, decodedAudio, 
                                          System.currentTimeMillis(), 
                                          decodedAudio.length);
    
    // 添加到混音器
    audioMixer.addAudioFrame(channelId, audioFrame);
}
```

#### 2.2 混音输出

```java
// 在定时处理中
private void processAudioOutput() {
    // 获取混音后的音频数据
    short[] mixedAudio = audioMixer.getMixedAudio();
    
    if (mixedAudio != null && mixedAudio.length > 0) {
        // 写入AudioTrack
        int bytesWritten = systemAudioPlayer.write(mixedAudio, 0, mixedAudio.length);
        if (bytesWritten > 0) {
            Log.d("AppWorker", "Mixed audio output: " + bytesWritten + " bytes");
        }
    }
}
```

## 🔧 高级配置

### 1. 同步参数调整

#### 1.1 时间同步配置

```java
// 自定义时间同步参数
public class CustomTimeSyncController extends TimeSyncController {
    private static final long CUSTOM_SYNC_INTERVAL_MS = 5;      // 5ms同步间隔
    private static final long CUSTOM_MAX_DRIFT_MS = 2;         // 最大漂移2ms
    
    @Override
    public void initializeSync() {
        // 自定义初始化逻辑
        super.initializeSync();
    }
}
```

#### 1.2 数据同步配置

```java
// 自定义数据同步参数
public class CustomDataSyncController extends DataSyncController {
    private static final int CUSTOM_BUFFER_SIZE = 2048;         // 2KB缓冲区
    private static final int CUSTOM_SYNC_TIMEOUT_MS = 50;      // 50ms超时
    
    @Override
    public void initializeDataSync() {
        // 自定义初始化逻辑
        super.initializeDataSync();
    }
}
```

### 2. 性能优化

#### 2.1 内存管理

```java
// 使用对象池减少GC压力
public class AudioFramePool {
    private final Queue<AudioFrame> framePool = new ConcurrentLinkedQueue<>();
    private final int maxPoolSize = 100;
    
    public AudioFrame getFrame(String channelId, short[] audioData, long timestamp, int sampleCount) {
        AudioFrame frame = framePool.poll();
        if (frame == null) {
            return new AudioFrame(channelId, audioData, timestamp, sampleCount);
        }
        
        // 重用现有帧
        return frame;
    }
    
    public void returnFrame(AudioFrame frame) {
        if (framePool.size() < maxPoolSize) {
            framePool.offer(frame);
        }
    }
}
```

#### 2.2 线程优先级优化

```java
// 设置音频线程优先级
public class AudioThreadManager {
    public static void setAudioThreadPriority(Thread thread) {
        android.os.Process.setThreadPriority(Process.THREAD_PRIORITY_URGENT_AUDIO);
    }
    
    public static void setHighThreadPriority(Thread thread) {
        android.os.Process.setThreadPriority(Process.THREAD_PRIORITY_URGENT_DISPLAY);
    }
}
```

### 3. 错误处理

#### 3.1 同步错误处理

```java
// 自定义错误处理
public class AudioSyncErrorHandler {
    private static final int MAX_SYNC_ERRORS = 5;
    private final Map<String, Integer> channelErrorCounts = new ConcurrentHashMap<>();
    
    public boolean handleSyncError(String channelId, Exception error) {
        int errorCount = channelErrorCounts.merge(channelId, 1, Integer::sum);
        
        if (errorCount > MAX_SYNC_ERRORS) {
            Log.e("AudioSync", "Too many sync errors for channel " + channelId + ", disabling");
            return false; // 禁用通道
        }
        
        Log.w("AudioSync", "Sync error for channel " + channelId + ": " + error.getMessage());
        return true; // 继续处理
    }
}
```

#### 3.2 自动恢复机制

```java
// 自动恢复管理器
public class AudioSyncRecoveryManager {
    private static final long RECOVERY_CHECK_INTERVAL_MS = 1000;
    private final Timer recoveryTimer;
    
    public void startRecoveryMonitoring() {
        recoveryTimer.scheduleAtFixedRate(new TimerTask() {
            @Override
            public void run() {
                checkAndRecoverSync();
            }
        }, RECOVERY_CHECK_INTERVAL_MS, RECOVERY_CHECK_INTERVAL_MS);
    }
    
    private void checkAndRecoverSync() {
        // 检查同步状态并执行恢复操作
        Log.d("AudioSync", "Checking sync recovery status");
    }
}
```

## 📊 监控和调试

### 1. 同步状态监控

```java
// 监控同步状态
public void monitorSyncStatus() {
    // 获取同步统计信息
    AudioSyncManager.SyncStatistics syncStats = audioSyncManager.getSyncStatistics();
    
    // 检查所有通道是否同步
    boolean allSynced = audioSyncManager.areAllChannelsSynced();
    
    // 获取混音统计信息
    AudioMixer.MixingStatistics mixingStats = audioMixer.getMixingStatistics();
    
    Log.i("AudioSync", "Sync status: " + syncStats);
    Log.i("AudioSync", "All channels synced: " + allSynced);
    Log.i("AudioSync", "Mixing stats: " + mixingStats);
}
```

### 2. 性能监控

```java
// 性能监控
public class AudioSyncPerformanceMonitor {
    private final Map<String, Long> channelLatencies = new ConcurrentHashMap<>();
    private final Map<String, Integer> channelDropCounts = new ConcurrentHashMap<>();
    
    public void recordChannelLatency(String channelId, long latency) {
        channelLatencies.put(channelId, latency);
    }
    
    public void recordChannelDrop(String channelId) {
        channelDropCounts.merge(channelId, 1, Integer::sum);
    }
    
    public void logPerformanceStats() {
        Log.i("AudioSync", "Channel latencies: " + channelLatencies);
        Log.i("AudioSync", "Channel drops: " + channelDropCounts);
    }
}
```

### 3. 调试工具

```java
// 调试工具类
public class AudioSyncDebugger {
    public static void logSyncState(AudioSyncManager syncManager) {
        AudioSyncManager.SyncStatistics stats = syncManager.getSyncStatistics();
        
        Log.d("AudioSyncDebug", "=== Audio Sync State ===");
        Log.d("AudioSyncDebug", "Total channels: " + stats.channelCount);
        
        for (Map.Entry<String, AudioSyncManager.SyncStatistics.ChannelStats> entry : 
             stats.getChannelStats().entrySet()) {
            String channelId = entry.getKey();
            AudioSyncManager.SyncStatistics.ChannelStats channelStats = entry.getValue();
            
            Log.d("AudioSyncDebug", "Channel " + channelId + ": " +
                  "drift=" + channelStats.syncDrift + "ms, " +
                  "frames=" + channelStats.frameCount + ", " +
                  "errors=" + channelStats.errorCount);
        }
    }
}
```

## 🎯 最佳实践

### 1. 通道管理

```java
// 通道管理最佳实践
public class ChannelManager {
    private final Map<String, ChannelInfo> channels = new ConcurrentHashMap<>();
    
    public boolean addChannel(String channelId, String codecType, float gain) {
        if (channels.containsKey(channelId)) {
            Log.w("ChannelManager", "Channel already exists: " + channelId);
            return false;
        }
        
        ChannelInfo info = new ChannelInfo(channelId, codecType, gain);
        channels.put(channelId, info);
        
        // 注册到同步管理器
        audioSyncManager.registerChannel(channelId);
        audioMixer.addChannel(channelId);
        audioMixer.setChannelGain(channelId, gain);
        
        Log.i("ChannelManager", "Added channel: " + channelId);
        return true;
    }
    
    public boolean removeChannel(String channelId) {
        ChannelInfo info = channels.remove(channelId);
        if (info == null) {
            return false;
        }
        
        // 从同步管理器注销
        audioSyncManager.unregisterChannel(channelId);
        audioMixer.removeChannel(channelId);
        
        Log.i("ChannelManager", "Removed channel: " + channelId);
        return true;
    }
}
```

### 2. 资源管理

```java
// 资源管理最佳实践
public class AudioSyncResourceManager {
    private final Set<String> activeChannels = new ConcurrentHashMap<String, Boolean>().keySet();
    
    public void cleanup() {
        // 清理所有通道
        for (String channelId : activeChannels) {
            audioSyncManager.unregisterChannel(channelId);
            audioMixer.removeChannel(channelId);
        }
        
        // 关闭同步管理器
        audioSyncManager.shutdown();
        audioMixer.shutdown();
        
        Log.i("AudioSync", "Resource cleanup completed");
    }
}
```

### 3. 异常处理

```java
// 异常处理最佳实践
public class AudioSyncExceptionHandler {
    public void handleException(String channelId, Exception e) {
        Log.e("AudioSync", "Exception in channel " + channelId, e);
        
        // 根据异常类型采取不同处理策略
        if (e instanceof OutOfMemoryError) {
            // 内存不足，清理缓冲区
            audioMixer.clearChannel(channelId);
        } else if (e instanceof InterruptedException) {
            // 中断异常，恢复线程状态
            Thread.currentThread().interrupt();
        } else {
            // 其他异常，记录并继续
            Log.w("AudioSync", "Unhandled exception type: " + e.getClass().getSimpleName());
        }
    }
}
```

## 🔄 完整集成示例

```java
// 完整的集成示例
public class MultiChannelAudioProcessor {
    private AudioSyncManager audioSyncManager;
    private AudioMixer audioMixer;
    private AudioTrack systemAudioPlayer;
    private Timer processTimer;
    
    public void initialize() {
        // 初始化混音器
        audioMixer = new AudioMixer();
        audioMixer.initialize();
        
        // 初始化同步管理器
        audioSyncManager = new AudioSyncManager();
        audioSyncManager.initialize();
        
        // 初始化AudioTrack
        initializeAudioTrack();
        
        // 启动处理定时器
        startProcessingTimer();
        
        Log.i("MultiChannelAudio", "Multi-channel audio processor initialized");
    }
    
    public void addChannel(String channelId, String codecType, float gain) {
        // 注册通道
        audioSyncManager.registerChannel(channelId);
        audioMixer.addChannel(channelId);
        audioMixer.setChannelGain(channelId, gain);
        
        Log.i("MultiChannelAudio", "Added channel: " + channelId);
    }
    
    public void processAudioFrame(String channelId, byte[] encodedFrame) {
        // 处理音频帧
        audioSyncManager.processAudioFrame(channelId, encodedFrame);
        
        // 解码音频
        short[] decodedAudio = decodeAudio(encodedFrame);
        
        // 创建音频帧
        AudioFrame audioFrame = new AudioFrame(channelId, decodedAudio, 
                                            System.currentTimeMillis(), 
                                            decodedAudio.length);
        
        // 添加到混音器
        audioMixer.addAudioFrame(channelId, audioFrame);
    }
    
    private void startProcessingTimer() {
        processTimer = new Timer("AudioProcessTimer");
        processTimer.scheduleAtFixedRate(new TimerTask() {
            @Override
            public void run() {
                processAudioOutput();
            }
        }, 10, 10); // 10ms间隔
    }
    
    private void processAudioOutput() {
        // 获取混音后的音频数据
        short[] mixedAudio = audioMixer.getMixedAudio();
        
        if (mixedAudio != null && mixedAudio.length > 0) {
            // 写入AudioTrack
            int bytesWritten = systemAudioPlayer.write(mixedAudio, 0, mixedAudio.length);
            if (bytesWritten > 0) {
                Log.d("MultiChannelAudio", "Mixed audio output: " + bytesWritten + " bytes");
            }
        }
    }
    
    public void shutdown() {
        // 停止定时器
        if (processTimer != null) {
            processTimer.cancel();
        }
        
        // 关闭同步管理器
        audioSyncManager.shutdown();
        audioMixer.shutdown();
        
        // 停止AudioTrack
        if (systemAudioPlayer != null) {
            systemAudioPlayer.stop();
            systemAudioPlayer.release();
        }
        
        Log.i("MultiChannelAudio", "Multi-channel audio processor shutdown");
    }
}
```

## 📝 总结

本使用指南提供了完整的多路解码线程同步集成方案，包括：

1. **基本集成**: 快速上手的集成步骤
2. **高级配置**: 自定义参数和性能优化
3. **监控调试**: 状态监控和性能分析
4. **最佳实践**: 通道管理、资源管理和异常处理
5. **完整示例**: 端到端的集成示例

通过遵循本指南，您可以成功地在Codec2 Talkie项目中实现多路音频的同步处理，确保音频质量和实时性。
