# 🎵 多路解码混音输出设计方案

## 1. 项目现状分析

### 1.1 当前架构特点
- **单路处理**: 目前只支持单路音频解码和播放
- **实时处理**: 使用高优先级音频线程 (`THREAD_PRIORITY_URGENT_AUDIO`)
- **装饰器模式**: 协议栈采用装饰器模式，便于扩展
- **统一接口**: Codec2和Opus使用相同的Protocol接口

### 1.2 技术限制
- **单AudioTrack**: 只有一个AudioTrack实例用于播放
- **同步处理**: 所有音频处理都在AppWorker单线程中
- **无混音能力**: 缺乏多路音频混音处理机制

## 2. 多路解码混音设计方案

### 2.1 整体架构设计

```
┌─────────────────────────────────────────────────────────────┐
│                   多路音频混音系统架构                        │
├─────────────────────────────────────────────────────────────┤
│  UI Layer: 多路音频控制界面                                  │
├─────────────────────────────────────────────────────────────┤
│  Audio Mixer Layer: 音频混音器                              │
│  ├─ MultiChannelAudioMixer                                 │
│  ├─ AudioChannelManager                                    │
│  └─ AudioBufferPool                                      │
├─────────────────────────────────────────────────────────────┤
│  Decoder Layer: 多路解码器                                  │
│  ├─ AudioChannelDecoder (Codec2/Opus)                      │
│  ├─ DecoderThreadPool                                      │
│  └─ AudioFrameQueue                                        │
├─────────────────────────────────────────────────────────────┤
│  Protocol Layer: 多路协议处理                              │
│  ├─ MultiChannelProtocol                                   │
│  ├─ ChannelRouter                                          │
│  └─ ProtocolDispatcher                                     │
├─────────────────────────────────────────────────────────────┤
│  Transport Layer: 多路传输                                  │
│  ├─ MultiTransportManager                                  │
│  └─ TransportChannel                                       │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 核心组件设计

#### 2.2.1 音频混音器 (AudioMixer)
```java
public class MultiChannelAudioMixer {
    private static final int MAX_CHANNELS = 8;           // 最大支持8路音频
    private static final int MIX_BUFFER_SIZE = 4096;     // 混音缓冲区大小
    private static final int SAMPLE_RATE = 8000;         // 采样率
    
    private final AudioChannel[] channels;               // 音频通道数组
    private final short[] mixBuffer;                     // 混音缓冲区
    private final AudioTrack outputTrack;                // 输出AudioTrack
    private final MixerThread mixerThread;               // 混音线程
    
    // 混音算法
    public void mixChannels() {
        Arrays.fill(mixBuffer, (short)0);
        
        for (AudioChannel channel : channels) {
            if (channel.isActive() && channel.hasData()) {
                short[] channelData = channel.getAudioData();
                for (int i = 0; i < mixBuffer.length; i++) {
                    // 防止溢出混音
                    int mixed = mixBuffer[i] + channelData[i];
                    mixBuffer[i] = (short)Math.max(Short.MIN_VALUE, 
                                                  Math.min(Short.MAX_VALUE, mixed));
                }
            }
        }
        
        outputTrack.write(mixBuffer, 0, mixBuffer.length);
    }
}
```

#### 2.2.2 音频通道管理器 (AudioChannelManager)
```java
public class AudioChannelManager {
    private final Map<String, AudioChannel> channels;    // 通道映射
    private final Map<String, DecoderThread> decoders;    // 解码器映射
    private final ChannelRouter router;                   // 通道路由器
    
    // 添加新通道
    public void addChannel(String channelId, String callsign, 
                          AudioCodec codec, int priority) {
        AudioChannel channel = new AudioChannel(channelId, callsign, codec, priority);
        DecoderThread decoder = new DecoderThread(channel);
        
        channels.put(channelId, channel);
        decoders.put(channelId, decoder);
        decoder.start();
    }
    
    // 移除通道
    public void removeChannel(String channelId) {
        AudioChannel channel = channels.remove(channelId);
        DecoderThread decoder = decoders.remove(channelId);
        
        if (decoder != null) {
            decoder.stop();
        }
        if (channel != null) {
            channel.close();
        }
    }
    
    // 设置通道优先级
    public void setChannelPriority(String channelId, int priority) {
        AudioChannel channel = channels.get(channelId);
        if (channel != null) {
            channel.setPriority(priority);
        }
    }
}
```

#### 2.2.3 多路解码器 (MultiChannelDecoder)
```java
public class AudioChannelDecoder extends Thread {
    private final AudioChannel channel;
    private final Protocol protocol;
    private final AudioCodec codec;
    private final AudioFrameQueue frameQueue;
    
    public AudioChannelDecoder(AudioChannel channel, Protocol protocol) {
        this.channel = channel;
        this.protocol = protocol;
        this.codec = channel.getCodec();
        this.frameQueue = new AudioFrameQueue(100); // 100帧缓冲
    }
    
    @Override
    public void run() {
        Process.setThreadPriority(Process.THREAD_PRIORITY_URGENT_AUDIO);
        
        while (!isInterrupted()) {
            try {
                // 接收压缩音频帧
                if (protocol.receive()) {
                    // 解码音频帧
                    short[] pcmFrame = decodeAudioFrame();
                    if (pcmFrame != null) {
                        // 添加到通道缓冲区
                        channel.addAudioData(pcmFrame);
                    }
                }
            } catch (IOException e) {
                Log.e(TAG, "Decoder error for channel " + channel.getId(), e);
                break;
            }
        }
    }
    
    private short[] decodeAudioFrame() {
        // 根据编解码器类型进行解码
        switch (codec) {
            case CODEC2:
                return decodeCodec2Frame();
            case OPUS:
                return decodeOpusFrame();
            default:
                return null;
        }
    }
}
```

### 2.3 协议栈扩展设计

#### 2.3.1 多路协议处理器 (MultiChannelProtocol)
```java
public class MultiChannelProtocol implements Protocol {
    private final Map<String, Protocol> channelProtocols;
    private final ProtocolCallback masterCallback;
    private final ChannelRouter router;
    
    public MultiChannelProtocol() {
        this.channelProtocols = new ConcurrentHashMap<>();
        this.router = new ChannelRouter();
    }
    
    @Override
    public void initialize(Transport transport, Context context, 
                         ProtocolCallback protocolCallback) throws IOException {
        this.masterCallback = protocolCallback;
        
        // 为每个通道创建独立的协议栈
        for (String channelId : getActiveChannels()) {
            Protocol channelProtocol = createChannelProtocol(channelId);
            ProtocolCallback channelCallback = createChannelCallback(channelId);
            channelProtocol.initialize(transport, context, channelCallback);
            channelProtocols.put(channelId, channelProtocol);
        }
    }
    
    private Protocol createChannelProtocol(String channelId) {
        // 根据通道配置创建协议栈
        Protocol proto = new Kiss();
        proto = new Ax25(proto);
        proto = new AudioCodec2(proto, getChannelPreferences(channelId));
        return proto;
    }
    
    private ProtocolCallback createChannelCallback(String channelId) {
        return new ProtocolCallback() {
            @Override
            protected void onReceivePcmAudio(String src, String dst, short[] pcmFrame) {
                // 路由到对应通道
                router.routeAudioFrame(channelId, src, dst, pcmFrame);
            }
            
            @Override
            protected void onReceiveCompressedAudio(String src, String dst, byte[] frame) {
                // 处理压缩音频帧
                router.routeCompressedFrame(channelId, src, dst, frame);
            }
            
            // 其他回调方法...
        };
    }
}
```

#### 2.3.2 通道路由器 (ChannelRouter)
```java
public class ChannelRouter {
    private final Map<String, AudioChannel> channelMap;
    private final Map<String, String> callsignToChannel; // 呼号到通道的映射
    
    public void routeAudioFrame(String channelId, String src, String dst, short[] pcmFrame) {
        AudioChannel channel = channelMap.get(channelId);
        if (channel != null) {
            // 更新呼号映射
            if (src != null) {
                callsignToChannel.put(src, channelId);
            }
            
            // 添加音频数据到通道
            channel.addAudioData(pcmFrame);
            
            // 更新通道状态
            channel.setLastActivity(System.currentTimeMillis());
            channel.setSourceCallsign(src);
        }
    }
    
    public void routeCompressedFrame(String channelId, String src, String dst, byte[] frame) {
        // 处理压缩音频帧路由
        AudioChannel channel = channelMap.get(channelId);
        if (channel != null) {
            // 解码压缩帧
            short[] pcmFrame = decodeCompressedFrame(channel, frame);
            if (pcmFrame != null) {
                routeAudioFrame(channelId, src, dst, pcmFrame);
            }
        }
    }
}
```

### 2.4 音频缓冲区管理

#### 2.4.1 音频帧队列 (AudioFrameQueue)
```java
public class AudioFrameQueue {
    private final BlockingQueue<AudioFrame> frameQueue;
    private final int maxSize;
    private final AtomicLong totalFrames;
    private final AtomicLong droppedFrames;
    
    public AudioFrameQueue(int maxSize) {
        this.maxSize = maxSize;
        this.frameQueue = new LinkedBlockingQueue<>(maxSize);
        this.totalFrames = new AtomicLong(0);
        this.droppedFrames = new AtomicLong(0);
    }
    
    public boolean offer(AudioFrame frame) {
        if (frameQueue.size() >= maxSize) {
            // 队列满，丢弃最老的帧
            frameQueue.poll();
            droppedFrames.incrementAndGet();
        }
        
        boolean success = frameQueue.offer(frame);
        if (success) {
            totalFrames.incrementAndGet();
        }
        return success;
    }
    
    public AudioFrame poll() {
        return frameQueue.poll();
    }
    
    public AudioFrame poll(long timeout, TimeUnit unit) throws InterruptedException {
        return frameQueue.poll(timeout, unit);
    }
}
```

#### 2.4.2 音频通道 (AudioChannel)
```java
public class AudioChannel {
    private final String id;
    private final String callsign;
    private final AudioCodec codec;
    private final CircularBuffer audioBuffer;
    private final AtomicInteger priority;
    private final AtomicBoolean active;
    private final AtomicLong lastActivity;
    private final AtomicReference<String> sourceCallsign;
    
    public AudioChannel(String id, String callsign, AudioCodec codec, int priority) {
        this.id = id;
        this.callsign = callsign;
        this.codec = codec;
        this.priority = new AtomicInteger(priority);
        this.active = new AtomicBoolean(true);
        this.lastActivity = new AtomicLong(System.currentTimeMillis());
        this.audioBuffer = new CircularBuffer(8192); // 8KB缓冲区
    }
    
    public void addAudioData(short[] pcmFrame) {
        if (active.get()) {
            audioBuffer.write(pcmFrame);
            lastActivity.set(System.currentTimeMillis());
        }
    }
    
    public short[] getAudioData(int samples) {
        return audioBuffer.read(samples);
    }
    
    public boolean hasData() {
        return audioBuffer.available() > 0;
    }
    
    public boolean isActive() {
        return active.get() && 
               (System.currentTimeMillis() - lastActivity.get()) < CHANNEL_TIMEOUT;
    }
}
```

### 2.5 混音算法设计

#### 2.5.1 基础混音算法
```java
public class AudioMixer {
    private static final int MAX_CHANNELS = 8;
    private static final int MIX_BUFFER_SIZE = 4096;
    
    public void mixChannels(AudioChannel[] channels, short[] outputBuffer) {
        // 清零输出缓冲区
        Arrays.fill(outputBuffer, (short)0);
        
        // 按优先级排序通道
        Arrays.sort(channels, (a, b) -> Integer.compare(b.getPriority(), a.getPriority()));
        
        // 混音处理
        for (AudioChannel channel : channels) {
            if (channel.isActive() && channel.hasData()) {
                short[] channelData = channel.getAudioData(MIX_BUFFER_SIZE);
                mixChannelData(outputBuffer, channelData, channel.getVolume());
            }
        }
        
        // 应用总音量控制
        applyMasterVolume(outputBuffer);
    }
    
    private void mixChannelData(short[] output, short[] input, float volume) {
        for (int i = 0; i < output.length; i++) {
            // 应用通道音量
            int sample = (int)(input[i] * volume);
            
            // 防止溢出
            int mixed = output[i] + sample;
            if (mixed > Short.MAX_VALUE) {
                output[i] = Short.MAX_VALUE;
            } else if (mixed < Short.MIN_VALUE) {
                output[i] = Short.MIN_VALUE;
            } else {
                output[i] = (short)mixed;
            }
        }
    }
}
```

#### 2.5.2 高级混音算法
```java
public class AdvancedAudioMixer extends AudioMixer {
    private final AudioCompressor compressor;
    private final AudioLimiter limiter;
    private final AudioEqualizer equalizer;
    
    public void mixChannels(AudioChannel[] channels, short[] outputBuffer) {
        // 基础混音
        super.mixChannels(channels, outputBuffer);
        
        // 动态范围压缩
        compressor.process(outputBuffer);
        
        // 限幅处理
        limiter.process(outputBuffer);
        
        // 均衡器处理
        equalizer.process(outputBuffer);
    }
}
```

### 2.6 用户界面设计

#### 2.6.1 多路音频控制界面
```java
public class MultiChannelAudioControl {
    private final Map<String, ChannelControl> channelControls;
    private final AudioMixer audioMixer;
    
    // 通道控制组件
    public static class ChannelControl {
        private String channelId;
        private String callsign;
        private boolean enabled;
        private float volume;
        private int priority;
        private AudioVisualizer visualizer;
        
        // 通道控制方法
        public void setEnabled(boolean enabled) { this.enabled = enabled; }
        public void setVolume(float volume) { this.volume = volume; }
        public void setPriority(int priority) { this.priority = priority; }
    }
    
    // 混音控制
    public void setMasterVolume(float volume) {
        audioMixer.setMasterVolume(volume);
    }
    
    public void setChannelVolume(String channelId, float volume) {
        ChannelControl control = channelControls.get(channelId);
        if (control != null) {
            control.setVolume(volume);
        }
    }
    
    public void setChannelPriority(String channelId, int priority) {
        ChannelControl control = channelControls.get(channelId);
        if (control != null) {
            control.setPriority(priority);
        }
    }
}
```

### 2.7 性能优化设计

#### 2.7.1 线程池管理
```java
public class AudioThreadPool {
    private final ExecutorService decoderPool;
    private final ExecutorService mixerPool;
    private final ScheduledExecutorService scheduler;
    
    public AudioThreadPool() {
        // 解码器线程池 - 高优先级
        this.decoderPool = Executors.newFixedThreadPool(MAX_CHANNELS, r -> {
            Thread t = new Thread(r, "AudioDecoder");
            t.setPriority(Thread.MAX_PRIORITY);
            return t;
        });
        
        // 混音器线程池 - 最高优先级
        this.mixerPool = Executors.newSingleThreadExecutor(r -> {
            Thread t = new Thread(r, "AudioMixer");
            t.setPriority(Thread.MAX_PRIORITY);
            return t;
        });
        
        // 调度器 - 中等优先级
        this.scheduler = Executors.newScheduledThreadPool(2, r -> {
            Thread t = new Thread(r, "AudioScheduler");
            t.setPriority(Thread.NORM_PRIORITY);
            return t;
        });
    }
}
```

#### 2.7.2 内存管理
```java
public class AudioBufferPool {
    private final Queue<short[]> bufferPool;
    private final int bufferSize;
    private final int poolSize;
    
    public AudioBufferPool(int bufferSize, int poolSize) {
        this.bufferSize = bufferSize;
        this.poolSize = poolSize;
        this.bufferPool = new ConcurrentLinkedQueue<>();
        
        // 预分配缓冲区
        for (int i = 0; i < poolSize; i++) {
            bufferPool.offer(new short[bufferSize]);
        }
    }
    
    public short[] acquire() {
        short[] buffer = bufferPool.poll();
        if (buffer == null) {
            // 池空，创建新缓冲区
            buffer = new short[bufferSize];
        }
        return buffer;
    }
    
    public void release(short[] buffer) {
        if (buffer != null && buffer.length == bufferSize) {
            // 清零缓冲区
            Arrays.fill(buffer, (short)0);
            bufferPool.offer(buffer);
        }
    }
}
```

## 3. 实现步骤

### 3.1 第一阶段：基础架构
1. **创建多路音频混音器**
   - 实现AudioMixer类
   - 实现AudioChannel类
   - 实现AudioBufferPool类

2. **扩展协议栈**
   - 创建MultiChannelProtocol类
   - 实现ChannelRouter类
   - 修改现有协议以支持多路

### 3.2 第二阶段：解码器扩展
1. **多路解码器**
   - 实现AudioChannelDecoder类
   - 创建DecoderThreadPool
   - 实现AudioFrameQueue类

2. **音频处理优化**
   - 实现高级混音算法
   - 添加音频压缩和限幅
   - 实现音频均衡器

### 3.3 第三阶段：用户界面
1. **多路音频控制界面**
   - 实现MultiChannelAudioControl类
   - 添加通道可视化
   - 实现混音控制面板

2. **性能优化**
   - 实现线程池管理
   - 优化内存使用
   - 添加性能监控

## 4. 技术挑战和解决方案

### 4.1 实时性保证
- **挑战**: 多路音频处理可能影响实时性
- **解决方案**: 使用高优先级线程池，优化混音算法

### 4.2 内存管理
- **挑战**: 多路音频需要大量内存
- **解决方案**: 实现缓冲区池，及时释放资源

### 4.3 同步问题
- **挑战**: 多路音频同步播放
- **解决方案**: 使用时间戳同步，实现音频帧对齐

### 4.4 音质保证
- **挑战**: 混音可能影响音质
- **解决方案**: 实现动态范围压缩，防止音频失真

## 5. 预期效果

### 5.1 功能特性
- **多路同时解码**: 支持最多8路音频同时解码
- **实时混音**: 多路音频实时混音输出
- **通道管理**: 独立的通道控制和管理
- **优先级控制**: 支持通道优先级设置

### 5.2 性能指标
- **延迟**: 保持现有延迟水平 (< 50ms)
- **CPU使用**: 多路处理CPU使用率 < 30%
- **内存使用**: 额外内存使用 < 50MB
- **音质**: 保持原有音质水平

## 6. 总结

这个设计方案在保持现有架构优势的基础上，通过模块化设计实现了多路音频解码和混音功能，为业余无线电通信提供了更强大的多路音频处理能力。

### 6.1 设计优势
- **模块化架构**: 清晰的组件分离，便于维护和扩展
- **性能优化**: 高效的线程池和内存管理
- **实时性保证**: 高优先级线程确保实时处理
- **音质保证**: 高级混音算法保证音质

### 6.2 技术亮点
- **装饰器模式**: 协议栈的灵活组合
- **缓冲区池**: 高效的内存管理
- **多线程处理**: 并行解码提高效率
- **智能路由**: 自动通道分配和管理

这个方案为Codec2 Talkie项目提供了完整的多路音频处理解决方案，能够显著提升业余无线电通信的效率和用户体验。

---

*设计方案完成时间：2024年*
*基于项目：Codec2 Talkie v1.88*
*技术栈：Android, Java, Codec2, Opus, 多路音频处理*
